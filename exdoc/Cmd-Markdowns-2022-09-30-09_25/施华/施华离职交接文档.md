# 施华离职交接文档

标签（空格分隔）： 施华

---

[TOC]
# **1.清单列表**
## **1.1 账号清单**
|物理机IP|账号|密码|用途|
|:----:|:----:|:----:|:----:|
|10.2.65.161|zhang|666666|功率预测计算环境|
|10.2.65.163|shihua|ae2151|闲置测试环境|
|10.2.65.164|zhang|666666|功率预测计算环境|
|10.2.65.188|root|ais188|功率预测计算环境|
|10.2.65.45|shihua|ae2151|算法测试数据库|
|10.2.65.46|shihua|ae2151|算法模型管理|
|10.2.65.47|shihua|ae2151|算法作业管理|
|10.3.110.71|phjqsh|meiQi@a1216|私有Pypi与Xwiki|
## **1.2 算法平台SEED相关监控WebUI**
|WebUI|IP|Port|
|:----:|:----:|:----:|
|Airflow|10.2.65.47|8080|
|Celery|10.2.65.47|5555|
|Kibana|10.2.65.46|5601|
|Consul|10.2.65.46|8500|
|MinIO|10.2.65.46|9000|
## **1.3 算法平台SEED后端组件服务**
|后端组件|IP|Port|
|:----:|:----:|:----:|
|MongoDB|10.2.65.46|27017|
|Redis|10.2.65.47|6901|
|MySQL|10.2.65.47|3306|
|ElasticSearch|10.2.65.46|9191|
## **1.4 项目代码清单**
每个项目分为Packages(包括代码),DOC(包括介绍文档，设计文档和代码文档)，以下为上线项目
|项目名称|GitLab|
|:----:|:----:|
|SEED-Exia|http://10.3.110.41/BM-ML/exiaalgorithmmanager|
|SEED-Veda|http://10.3.110.41/BM-ML/veda|
|SEED-Kyrios|http://10.3.110.41/BM-ML/kyrios|
|SEED-Ptolemy|http://10.3.110.41/BM-ML/ptolemy|
|Raiser|http://10.3.110.41/BM-ML/ptolemy|
|StarAtlas|http://10.3.110.41/BM-ML/staratlas|
|LabelTool|http://10.3.110.41/BM-ML/labeltool|
|PowerForecast|http://10.3.110.41/BM-ML/powerforecast|
|WindSpeedRevise|http://10.3.110.41/BM-ML/windspeedrevise|
|OptimizationModel|http://10.3.110.41/BM-ML/optimization_model|
以下为未上线项目
|项目名称|代码|文档|
|:----:|:----:|
|BMA气象融合|D:\AEwork\BeyasianModelAverageFusion||
|风速修正|D:\AEwork\power_forecast\WindSpeedReviseDemo|D:\美启电力\项目\风电功率预测\文献资料\风速修正|
|mlflow|D:\AEwork\mlflow||

# **2.算法运维相关**
+ SEED相关使用可见DOC/OfficialDoc/build/html/index.html对应的快速指南部分
+ 后端运维主要以airflow和计算环境的执行脚本为主，该部分可参见以下目录结构
```
位置:10.2.65.188:/home/zhang/myprojects/

.
├── deepar_solar		#光伏功率预测（数据库：solar_power_forecast）
│   ├── data_statistics.py          	#实时和预测数据统计
│   ├── get_power.py		#获取实时功率	
│   ├── get_weather.py		#获取预测气象数据和历史数据
│   ├── models			#本地模型地址
│   ├── run_forecast.py		#功率预测
│   ├── run_target.py		#指标计算
│   ├── run_train.py			#模型训练
│   ├── scheduler.py			#预测设置监控和调度修改DAG
│   ├── sh_files			#airflow调度shell文件地址
│   ├── Utils			#脚本运行辅助函数和数据库配置文件夹

├── deepar_wind		#风电功率预测（数据库：wind_power_forecast）
│   ├── data_statistics.py		#实时和预测数据统计
│   ├── forecast_statistics.py		#统计前一日预测数据是否缺失，缺失补齐
│   ├── get_power.py		#获取实时功率
│   ├── get_weather.py		#获取预测气象数据和历史数据
│   ├── model			#本地模型地址
│   ├── run_anemometer_tower.py	#测风塔数据统计
│   ├── run_forecast_multi.py
│   ├── run_forecast.py		#功率预测
│   ├── run_get_target.py		#指标计算
│   ├── run_station_write.py		#通过风机计算电站预测和实测数据
│   ├── run_train.py			#模型训练
│   ├── scheduler.py			#预测设置监控和调度修改DAG
│   ├── sh_files			#airflow调度shell文件地址
│   ├── station_forecast.py		#通过预测场站风速预测场站功率方法
│   ├── Utils			#脚本运行辅助函数和数据库配置文件夹
│   └── ws_model
└── flask_app_project	#airflow调度接口
    ├── dags			#dag生成地址
    ├── flask_app.py			#接口文件
    ├── solar_data_statistics_template
    ├── solar_scheduler_template
    ├── solar_short_forecast_power_template
    ├── solar_super_short_forecast_power_template
    ├── test.py
    ├── Utils			#脚本运行辅助函数文件夹
    ├── wind_anemometer_tower_template
    ├── wind_data_statistics_template
    ├── wind_scheduler_template
    ├── wind_short_forecast_power_template
    ├── wind_super_short_forecast_power_template
    └── wind_target_run_template

17 directories, 45 files
```

# **3.算法部署相关**
+ 打包本地linux系统，构建docker镜像

+ 进入本地系统，运行命令
```
　　sudo su

　　cd /

　　tar -cvpzf /media/system.tar --exclude=/proc --exclude=/lost+found --exclude=/mnt --exclude=/sys --exclude=/media /
```
+ 拷贝system.tar到docker宿主机

+ 在docker宿主机上，运行命令

　　docker import system.tar my_system_img

+ docker安装

+ 存储，调度，计算环境皆需安装docker deb文件
```
sudo dpkg -i containerd.io_1.2.2-3_amd64.deb

sudo dpkg -i docker-ce-cli_19.03.9~3-0~ubuntu-bionic_amd64.deb

sudo dpkg -i docker-ce_19.03.6_3-0_ubuntu-bionic_amd64.deb
```

+ 
作业管理服务器（47):
1.airlfow
2.mysql
3.celery
4.redis
模型管理服务器（46）：
1.MinIO
2.MongoDB
3.consul
4.Elasticsearch
5.kibana

+ 模型管理服务器部署

+ 导入运行镜像文件
```
sudo docker import ModelManagementImage_1.0.tar system_46

sudo docker images
```
+ 运行docker镜像，设置对应端口
```
sudo docker run  -itd --privileged -p 9000:9000 -p 10022:22 -p 27017:27017 --name system_46 system_46:latest /usr/sbin/init
```
+ 查看docker container ID，进入容器
```
sudo docker ps

sudo docker exec -it 775c7c9ee1e1(containerID)  /bin/bash

vim /etc/mongodb.conf

> 将bind_ip 127.0.0.1 修改为0.0.0.0

systemctl start mongodb

mongo

## 配置用户

> use admin
>
> 
>
> > db.createUser(
> > ... {
> > ...   user: "admin",
> > ...   pwd: "admin",
> > ...   roles: [ { role: "userAdminAnyDatabase", db: "admin"} ]
> > ... }
> > ... )

systemctl restart mongodb

cd /10.2.45.46/shells/minio

nohup ./minio server /data 2>1&
```
+ 通过9000端口添加modellibrary的bucket

+ 作业管理服务器部署

+ 导入运行镜像文件
```
sudo docker import JobManagementImage_1.0.tar.tar system_47

sudo docker images
```
+ 运行docker镜像，设置对应端口
```
sudo docker run  -itd --privileged -p 8080:8080 -p 10022:22 -p 9000:9000 -p 5555:5555 -p 3306:3306 --name system_47 system_47:latest /usr/sbin/init
```
+ 查看docker container ID，进入容器
```
sudo docker ps

#sudo docker cp minio containerID:/

sudo docker exec -it 775c7c9ee1e1(containerID)  /bin/bash

#cd /

#chmod +x minio

#mv minio /usr/bin/

#cd /root/airflow

#mkdir dags

cd ~

nohup minio server airflow 2>1&

cd /media/airflow/redis-6.0.5/src

#vim redis.conf

> 修改redis.conf`
>
> > 注释掉bind:127.0.0.1 或者修改为0.0.0.0
>
> > 修改保护模式为noprotected-mode no

nohup ./redis-server redis.conf 2>1&

sudo service mysql start

airflow initdb

nohup airflow scheduler 2>1&

nohup airflow worker 2>1&

nohup airflow flower 2>1&

nohup airflow webserver -p 8080 2>1&
```
+ 计算环境部署

+ 导入运行镜像文件
```
sudo docker import CalulationImage_1.0.tar system_calulation

sudo docker images
```
## 运行docker镜像，设置对应端口
```
sudo docker run  -itd --privileged -p 5000:5000  -p 10022:22 --name system_calulation system_calulation:latest /usr/sbin/init

sudo docker ps

sudo docker exec -it 775c7c9ee1e1(containerID)  /bin/bash
```
+ 将运行程序放置镜像内部：
```
sudo docker cp test/ fe05be6b762c:/
```

# **4.目前问题和后续工作改进方向**
+ 冷热数据问题，目前采用每个月手动分库分表操作，后续可以采用读写分离，分库分表，使用时序数据库处理数据。
+ 执行脚本代码过长维护困难问题，后续可使用Kyrios重新将代码细分组合配置。
+ 计算环境问题，目前生产采用的是单机计算，未使用分布式计算框架，后续可以采用Ray或Dask结合Kyrios来编排执行脚本模板
+ 后端组件监控问题，目前对于SEED后端组件没有进行监控，后续可采用Supervisor和Cesi将SEED各个组件监控起来。







